# API å‚è€ƒæ¦‚è¿°

Hypergraph-DB æä¾›äº†ç®€æ´è€Œå¼ºå¤§çš„ API æ¥åˆ›å»ºã€æ“ä½œå’ŒæŸ¥è¯¢è¶…å›¾ã€‚æœ¬èŠ‚æä¾›æ‰€æœ‰å¯ç”¨ç±»å’Œæ–¹æ³•çš„å®Œæ•´å‚è€ƒã€‚

## æ ¸å¿ƒç±»

### HypergraphDB

ä¸»è¦çš„è¶…å›¾æ•°æ®åº“ç±»ï¼Œæä¾›å®Œæ•´çš„è¶…å›¾æ“ä½œåŠŸèƒ½ã€‚

```python
from hyperdb import HypergraphDB

# åˆ›å»ºæ–°çš„è¶…å›¾
hg = HypergraphDB()

# ä»æ–‡ä»¶åŠ è½½ç°æœ‰è¶…å›¾
hg = HypergraphDB("my_hypergraph.hgdb")
```

[æŸ¥çœ‹å®Œæ•´ HypergraphDB API â†’](hypergraph.zh.md)

### BaseHypergraphDB

æŠ½è±¡åŸºç±»ï¼Œå®šä¹‰äº†è¶…å›¾æ•°æ®åº“çš„æ ¸å¿ƒæ¥å£ã€‚

```python
from hyperdb import BaseHypergraphDB

# ä¸»è¦ç”¨äºç»§æ‰¿å’Œæ‰©å±•
class CustomHypergraphDB(BaseHypergraphDB):
    # è‡ªå®šä¹‰å®ç°
    pass
```

[æŸ¥çœ‹å®Œæ•´ BaseHypergraphDB API â†’](base.zh.md)

## å¿«é€Ÿ API å‚è€ƒ

### åŸºç¡€æ“ä½œ

| æ–¹æ³•                 | æè¿°         | ç¤ºä¾‹                                       |
| -------------------- | ------------ | ------------------------------------------ |
| `add_v(id, data)`    | æ·»åŠ é¡¶ç‚¹     | `hg.add_v("A", {"name": "Alice"})`         |
| `add_e(tuple, data)` | æ·»åŠ è¶…è¾¹     | `hg.add_e(("A", "B"), {"type": "friend"})` |
| `remove_v(id)`       | ç§»é™¤é¡¶ç‚¹     | `hg.remove_v("A")`                         |
| `remove_e(tuple)`    | ç§»é™¤è¶…è¾¹     | `hg.remove_e(("A", "B"))`                  |
| `v(id)`              | è·å–é¡¶ç‚¹æ•°æ® | `data = hg.v("A")`                         |
| `e(tuple)`           | è·å–è¶…è¾¹æ•°æ® | `data = hg.e(("A", "B"))`                  |

### æŸ¥è¯¢æ“ä½œ

| æ–¹æ³•                | æè¿°             | ç¤ºä¾‹                                   |
| ------------------- | ---------------- | -------------------------------------- |
| `has_v(id)`         | æ£€æŸ¥é¡¶ç‚¹æ˜¯å¦å­˜åœ¨ | `hg.has_v("A")`                        |
| `has_e(tuple)`      | æ£€æŸ¥è¶…è¾¹æ˜¯å¦å­˜åœ¨ | `hg.has_e(("A", "B"))`                 |
| `degree_v(id)`      | é¡¶ç‚¹åº¦æ•°         | `deg = hg.degree_v("A")`               |
| `degree_e(tuple)`   | è¶…è¾¹å¤§å°         | `size = hg.degree_e(("A", "B"))`       |
| `nbr_v(id)`         | é¡¶ç‚¹çš„é‚»å±…é¡¶ç‚¹   | `neighbors = hg.nbr_v("A")`            |
| `nbr_e_of_v(id)`    | é¡¶ç‚¹çš„é‚»å±…è¶…è¾¹   | `edges = hg.nbr_e_of_v("A")`           |
| `nbr_v_of_e(tuple)` | è¶…è¾¹çš„é‚»å±…é¡¶ç‚¹   | `vertices = hg.nbr_v_of_e(("A", "B"))` |

### å…¨å±€å±æ€§

| å±æ€§    | æè¿°     | ç¤ºä¾‹                  |
| ------- | -------- | --------------------- |
| `all_v` | æ‰€æœ‰é¡¶ç‚¹ | `vertices = hg.all_v` |
| `all_e` | æ‰€æœ‰è¶…è¾¹ | `edges = hg.all_e`    |
| `num_v` | é¡¶ç‚¹æ•°é‡ | `count = hg.num_v`    |
| `num_e` | è¶…è¾¹æ•°é‡ | `count = hg.num_e`    |

### æŒä¹…åŒ–æ“ä½œ

| æ–¹æ³•                      | æè¿°                | ç¤ºä¾‹                                                      |
| ------------------------- | ------------------- | --------------------------------------------------------- |
| `save(path)`              | ä¿å­˜åˆ°æ–‡ä»¶          | `hg.save("graph.hgdb")`                                   |
| `load(path)`              | ä»æ–‡ä»¶åŠ è½½          | `hg.load("graph.hgdb")`                                   |
| `to_hif(filepath=None)`   | å¯¼å‡ºä¸º HIF æ ¼å¼     | `hif_data = hg.to_hif()` æˆ– `hg.to_hif("graph.hif.json")` |
| `save_as_hif(filepath)`   | ä¿å­˜ä¸º HIF æ ¼å¼æ–‡ä»¶ | `hg.save_as_hif("graph.hif.json")`                        |
| `from_hif(hif_data)`      | ä» HIF æ ¼å¼æ•°æ®åŠ è½½ | `hg.from_hif(hif_data)` æˆ– `hg.from_hif(json_string)`     |
| `load_from_hif(filepath)` | ä» HIF æ ¼å¼æ–‡ä»¶åŠ è½½ | `hg.load_from_hif("graph.hif.json")`                      |

### å¯è§†åŒ–

| æ–¹æ³•                       | æè¿°       | ç¤ºä¾‹                 |
| -------------------------- | ---------- | -------------------- |
| `draw(port, open_browser)` | å¯åŠ¨å¯è§†åŒ– | `hg.draw(port=8080)` |

[æŸ¥çœ‹å®Œæ•´å¯è§†åŒ– API â†’](visualization.zh.md)

## å¸¸ç”¨æ¨¡å¼

### åˆ›å»ºå’Œå¡«å……è¶…å›¾

```python
from hyperdb import HypergraphDB

# åˆ›å»ºè¶…å›¾
hg = HypergraphDB()

# æ‰¹é‡æ·»åŠ é¡¶ç‚¹
users = [
    ("user1", {"name": "å¼ ä¸‰", "age": 25}),
    ("user2", {"name": "æå››", "age": 30}),
    ("user3", {"name": "ç‹äº”", "age": 28})
]

for user_id, user_data in users:
    hg.add_v(user_id, user_data)

# æ‰¹é‡æ·»åŠ è¶…è¾¹
relationships = [
    (("user1", "user2"), {"type": "æœ‹å‹"}),
    (("user1", "user2", "user3"), {"type": "é¡¹ç›®å›¢é˜Ÿ"})
]

for vertices, edge_data in relationships:
    hg.add_e(vertices, edge_data)
```

### æŸ¥è¯¢å’Œåˆ†æ

```python
# åˆ†æè¶…å›¾ç»“æ„
print(f"è¶…å›¾åŒ…å« {hg.num_v} ä¸ªé¡¶ç‚¹å’Œ {hg.num_e} æ¡è¶…è¾¹")

# æ‰¾å‡ºåº¦æ•°æœ€é«˜çš„é¡¶ç‚¹
most_connected = max(hg.all_v, key=lambda v: hg.degree_v(v))
print(f"æœ€æ´»è·ƒçš„ç”¨æˆ·: {hg.v(most_connected)['name']}")

# åˆ†æè¶…è¾¹å¤§å°åˆ†å¸ƒ
edge_sizes = [hg.degree_e(e) for e in hg.all_e]
avg_size = sum(edge_sizes) / len(edge_sizes)
print(f"å¹³å‡è¶…è¾¹å¤§å°: {avg_size:.2f}")
```

### æ•°æ®æ›´æ–°

```python
# æ›´æ–°é¡¶ç‚¹æ•°æ®
hg.update_v("user1", {"age": 26, "location": "åŒ—äº¬"})

# æ›´æ–°è¶…è¾¹æ•°æ®
hg.update_e(("user1", "user2"), {"strength": 0.9})

# æ£€æŸ¥æ›´æ–°ç»“æœ
updated_user = hg.v("user1")
updated_edge = hg.e(("user1", "user2"))
```

### HIF æ ¼å¼å¯¼å…¥å¯¼å‡º

Hypergraph-DB æ”¯æŒ HIF (Hypergraph Interchange Format) æ ¼å¼ï¼Œç”¨äºæ ‡å‡†åŒ–çš„è¶…å›¾æ•°æ®äº¤æ¢ã€‚

#### å¯¼å‡ºåˆ° HIF æ ¼å¼

```python
# å¯¼å‡ºå¹¶ä¿å­˜åˆ°æ–‡ä»¶
hg.to_hif("my_hypergraph.hif.json")

# æˆ–è€…ä½¿ç”¨ save_as_hif æ–¹æ³•
hg.save_as_hif("my_hypergraph.hif.json")
```

#### ä» HIF æ ¼å¼å¯¼å…¥

```python
hg.load_from_hif("my_hypergraph.hif.json")
```

## é”™è¯¯å¤„ç†

### å¸¸è§å¼‚å¸¸

```python
try:
    # å°è¯•æ·»åŠ é¡¶ç‚¹
    hg.add_v("user1", {"name": "å¼ ä¸‰"})

    # å°è¯•æ·»åŠ è¶…è¾¹ï¼ˆé¡¶ç‚¹å¿…é¡»å·²å­˜åœ¨ï¼‰
    hg.add_e(("user1", "user999"), {"type": "æœ‹å‹"})

except AssertionError as e:
    print(f"æ–­è¨€é”™è¯¯: {e}")

except KeyError as e:
    print(f"é”®é”™è¯¯: {e}")

except Exception as e:
    print(f"å…¶ä»–é”™è¯¯: {e}")
```

### æœ€ä½³å®è·µ

1. **é¡¶ç‚¹ ID**: ä½¿ç”¨å¯å“ˆå¸Œçš„ã€æœ‰æ„ä¹‰çš„æ ‡è¯†ç¬¦
2. **æ•°æ®éªŒè¯**: åœ¨æ·»åŠ æ•°æ®å‰è¿›è¡ŒéªŒè¯
3. **å¼‚å¸¸å¤„ç†**: é€‚å½“å¤„ç†å¯èƒ½çš„é”™è¯¯
4. **æ€§èƒ½è€ƒè™‘**: å¯¹äºå¤§å‹æ•°æ®é›†ï¼Œè€ƒè™‘æ‰¹é‡æ“ä½œ

## ç±»å‹æç¤º

Hypergraph-DB æ”¯æŒç±»å‹æç¤ºä»¥æä¾›æ›´å¥½çš„å¼€å‘ä½“éªŒï¼š

```python
from typing import Dict, Any, Tuple, List, Set
from hyperdb import HypergraphDB

def analyze_hypergraph(hg: HypergraphDB) -> Dict[str, Any]:
    """åˆ†æè¶…å›¾å¹¶è¿”å›ç»Ÿè®¡ä¿¡æ¯"""
    return {
        "num_vertices": hg.num_v,
        "num_edges": hg.num_e,
        "avg_degree": sum(hg.degree_v(v) for v in hg.all_v) / hg.num_v
    }
```

## æ‰©å±• API

### è‡ªå®šä¹‰åˆ†ææ–¹æ³•

```python
from hyperdb import HypergraphDB

class AnalyticsHypergraphDB(HypergraphDB):
    """æ‰©å±•äº†åˆ†æåŠŸèƒ½çš„è¶…å›¾æ•°æ®åº“"""

    def clustering_coefficient(self, vertex_id: str) -> float:
        """è®¡ç®—é¡¶ç‚¹çš„èšç±»ç³»æ•°"""
        neighbors = self.nbr_v(vertex_id)
        if len(neighbors) < 2:
            return 0.0

        # è®¡ç®—é‚»å±…ä¹‹é—´çš„è¿æ¥
        connections = 0
        total_possible = len(neighbors) * (len(neighbors) - 1) // 2

        for edge in self.all_e:
            edge_vertices = self.nbr_v_of_e(edge)
            if len(edge_vertices.intersection(neighbors)) >= 2:
                connections += 1

        return connections / total_possible if total_possible > 0 else 0.0

    def k_core_decomposition(self, k: int) -> Set[str]:
        """k-æ ¸åˆ†è§£ï¼šæ‰¾å‡ºåº¦æ•°è‡³å°‘ä¸ºkçš„é¡¶ç‚¹"""
        return {v for v in self.all_v if self.degree_v(v) >= k}
```

## ä¸‹ä¸€æ­¥

- **[HypergraphDB è¯¦ç»† API](hypergraph.zh.md)**: ä¸»ç±»çš„å®Œæ•´æ–¹æ³•æ–‡æ¡£
- **[BaseHypergraphDB API](base.zh.md)**: åŸºç±»å’Œæ‰©å±•æŒ‡å—
- **[å¯è§†åŒ– API](visualization.zh.md)**: å¯è§†åŒ–åŠŸèƒ½è¯¦è§£
- **[ç¤ºä¾‹ä»£ç ](../examples/basic-usage.zh.md)**: å®é™…ä½¿ç”¨æ¡ˆä¾‹

é€šè¿‡è¿™äº› APIï¼Œæ‚¨å¯ä»¥å……åˆ†åˆ©ç”¨ Hypergraph-DB çš„å¼ºå¤§åŠŸèƒ½æ¥å»ºæ¨¡å’Œåˆ†æå¤æ‚çš„å¤šå…ƒå…³ç³»ï¼ğŸš€
